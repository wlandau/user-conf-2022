---
title: "data version control for the {targets} R package"
author: "Will Landau"
output:
  xaringan::moon_reader:
    nature:
      highlightLines: yes
---

<style>
.inverse {
background-color: transparent;
text-shadow: 0 0 0px transparent;
}
.title-slide {
vertical-align: bottom !important; 
text-align: center !important;
}
.title-slide h1 {
position: absolute;
top: -50px;
left: 0;
right: 0;
width: 100%;
line-height: 4em;
color: #666666;
}
.title-slide h2 {
position: absolute;
top: 0px;
right: 0;
left: 0;
line-height: 6em;
color: #666666;
}
.title-slide h3 {
position: absolute;
top: 400px;
right: 0;
left: 0;
line-height: 6em;
color: #666666;
}
.title-slide {
background-color: white;
background-image: url('images/gittargets.png');
background-repeat: no-repeat;
background-size: 25%;
background-position: 25px 0px 0px 0px;
}
.remark-slide-content:after {
content: "Copyright Eli Lilly and Company";
position: absolute;
bottom: -5px;
left: 20px;
height: 40px;
width: 100%;
font-family: Helvetica, Arial, sans-serif;
font-size: 0.7em;
color: #666666;
background-repeat: no-repeat;
background-size: contain;
}
</style>

```{r, include = FALSE, echo = FALSE}
set.seed(0)
suppressPackageStartupMessages({
  library(gittargets)
  library(targets)
})
knitr::opts_chunk$set(
  cache = FALSE,
  comment = "#>",
  fig.width = 10, 
  fig.height = 5
)
```

# Pipeline tools

* Existing pipeline tools: https://github.com/pditommaso/awesome-pipeline
* Most are language-agnostic or designed for Python or the shell.
* Different pipline toolkits have different priorities and tradeoffs:

![](./images/tooltypes.png)

---

# {targets}

<center>
<img src="./images/targets.png" height = "400px">
</center>

* Make-like pipeline tool for R.
* New developments add Airflow-like capabilities.

---

# Ecosystem around {targets}

<center>
<img src="./images/targetopia.png" height = "400px">
</center>

---

# {targets} data store

```
_targets/ # Can be customized with tar_config_set().
├── meta/
├────── meta
├────── process
├────── progress
├── objects/
├────── target1 
├────── target2
├────── branching_target_c7bcb4bd
├────── branching_target_285fb6a9
├────── branching_target_874ca381
├── scratch/ # tar_make() deletes this folder after it finishes.
└── user/ # custom user storage for gittargets data version control.
```

---

# Default data store tradeoffs are Make-like

<center>
<img src="./images/scale.png" height = "300px">
</center>

* Compactly represents the *current* state of the pipeline.
* Does not contain historical data from past runs.

---

# Current pipeline is up to date...

```{r, eval = FALSE}
# _targets.R
library(targets)
list(
  tar_target(data, airquality),
  tar_target(model, lm(Ozone ~ Wind, data = data))
)
```

```{r, eval = FALSE}
tar_make() # All targets are up to date.
#> ✓ skip target data
#> ✓ skip target model
#> ✓ skip pipeline
```

---

# But checking out old code invalidates a target!

```{r, eval = FALSE}
gert::git_branch_checkout(branch = "old-code-branch")
```

```{r, eval = FALSE}
# _targets.R
library(targets)
list(
  tar_target(data, airquality),
  tar_target(model, lm(Ozone ~ Temp, data = data)) # old model #<<
)
```

```{r, eval = FALSE}
tar_make() # The model is not up to date with the checked-out code.
#> ✓ skip target data
#> • start target model # (Didn't I already run this ages ago?) #<<
#> • built target model
#> • end pipeline
```

---

# Solution 1: cloud storage

```{r, eval = FALSE}
# _targets.R file
library(targets)
tar_option_set(resources = tar_resources(
  aws = tar_resources_aws(bucket = "my_versioned_bucket")
))
list(
  tar_target(data, get_data(), format = "aws_parquet"),
  tar_target(model, run_model(data), format = "aws_qs")
)
```

* How to configure a cloud-backed version-aware pipeline:
    1. Create an AWS S3 bucket and turn on versioning.
    2. Supply the bucket to AWS resources.
    3. Use AWS-backed storage formats.
    4. Commit `_targets/meta/meta` to source code verison control.
* Reverting to an earlier code commit recovers the up-to-date targets built with the old code.
* Details: <https://books.ropensci.org/targets/storage_amazon.html>.
* Google Cloud Storage support under development by [Mark Edmondson](https://github.com/MarkEdmondson1234).

---

# Solution 2: {gittargets}

<center>
<img src="./images/gittargets.png" height = "300px">
</center>

* Put the data store under version control.
* Sync code commits with data commits.
* Switch commits and branches without invalidating the pipeline.
* Keep a historical record of the data from key milestones of the project.
* Documentation: https://docs.ropensci.org/gittargets/

---

# {gittargets} workflow

1. `targets::tar_make()` (or `tar_make_clustermq()` or `tar_make_future()`): run pipeline at least once.
2. `gert::git_commit()`: commit code.
3. `gittargets::tar_git_init()`: initialize data repository.
4. `gittargets::tar_git_snapshot()`: create a data snapshot for the current code commit.
5. `gittargets::tar_git_checkout()`: revert the data to the appropriate prior snapshot.

---

# Initialize data repository

* Assumes the pipeline ran at least once.

```{r, eval = FALSE}
tar_git_init()
#> ✔ Created data store Git repository
#> ✔ Wrote to _targets/.gitattributes for git-lfs: <https://git-lfs.github.com>.
#> ✔ Created stub commit without data.
#> • Run tar_git_snapshot() to put the data files under version control.
```

---

# Snapshot the data


```{r, eval = FALSE}
tar_git_snapshot()
#> • Creating data branch code=af36d7301844831adc4cdedffbcb802cecebb0d1.
#> • Staging data files.
#> ✔ Staged 6 files in the data store.
#> • Committing data changes.
#> ✔ Created new data snapshot b0641526e062fee82e5d3d2c88163ea4823bc1b8.
#> • Packing references.
```
---

# Snapshot model

<center>
<img src="./images/snapshot-model-git.png" height = "450px">
</center>

---

# Check out old code

```{r, eval = FALSE}
gert::git_branch_checkout("old-code-branch")
```

* Find code commits with data snapshots:

```{r, eval = FALSE}
tar_git_log()
#> # A tibble: 2 × 6
#>   message_code  message_data time_code           time_data           commit_code
#>   <chr>         <chr>        <dttm>              <dttm>              <chr>      
#> 1 Begin analyz… Begin analy… 2022-02-13 01:32:53 2022-02-13 01:32:55 af36d73018…
#> 2 Switch to UK… Switch to U… 2022-02-13 01:32:56 2022-02-13 01:32:57 e650867f85…
#> # … with 1 more variable: commit_data <chr>
```

---

# Check out matching old data

```{r, eval = FALSE}
tar_git_checkout()
#> ✔ Checked out data snapshot b0641526e062fee82e5d3d2c88163ea4823bc1b8.
#> • Code commit: code=af36d7301844831adc4cdedffbcb802cecebb0d1
#> • Message: Begin analyzing the airquality dataset
#> • Resetting to HEAD of checked-out snapshot.
```

```{r, eval = FALSE}
tar_make() # The old data files are synced with the old code.
#> ✓ skip target data
#> ✓ skip target model
#> ✓ skip pipeline
```
